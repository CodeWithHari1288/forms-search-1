import React, { useState } from "react";
import { CopilotKit } from "@copilotkit/react-core";
import { useCopilotChat } from "@copilotkit/react-core"; // headless chat API
import { CopilotChat } from "@copilotkit/react-ui";

const RUNTIME = "http://localhost:8000/chat"; // your API

function HeadlessControlledChat() {
  const { messages, setMessages, appendMessage } = useCopilotChat(); // headless
  const [sending, setSending] = useState(false);

  async function sendUserMessage(text) {
    // 1) Update local UI immediately
    const next = [...messages, { role: "user", content: text }];
    setMessages(next);

    // 2) Build a MINIMAL payload to send — you control this
    const minimal = next
      .filter(m => m.role === "user" || m.role === "assistant") // drop system/tool
      .slice(-6);                                               // last 6 turns only
      // .map(m => ({ role: m.role, content: redact(m.content) })) // if you need redaction

    setSending(true);
    try {
      const res = await fetch(RUNTIME, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ messages: minimal }),
      });
      const data = await res.json();
      // 3) Append assistant reply from your API
      if (data?.message) appendMessage(data.message);
    } finally {
      setSending(false);
    }
  }

  return (
    <div style={{ height: 520, width: 420 }}>
      <CopilotChat
        onSend={sendUserMessage}     // ← use our custom sender
        labels={{ title: "Controlled Copilot" }}
        placeholder={sending ? "Thinking…" : "Type your message…"}
      />
    </div>
  );
}

export default function App() {
  return (
    <CopilotKit copilotRuntimeUrl={RUNTIME}>
      <HeadlessControlledChat />
    </CopilotKit>
  );
}





// runtime/index.js
import express from "express";
import cors from "cors";
import { CopilotRuntime, copilotRuntimeNodeHttpEndpoint } from "@copilotkit/runtime";

const app = express();
app.use(cors({ origin: ["http://localhost:3000", "http://127.0.0.1:3000"] }));

// Local model via Ollama
process.env.OPENAI_API_KEY  ||= "ollama";                    // dummy
process.env.OPENAI_BASE_URL ||= "http://localhost:11434/v1"; // ollama serve
process.env.OPENAI_MODEL    ||= "llama3.2";                  // ollama pull llama3.2

const runtime = new CopilotRuntime({
  system: "You are helpful and concise.",
});

// Optional demo tool; remove if you just want plain chat
runtime.registerAction({
  name: "echo_tool",
  description: "Echo the latest user input.",
  parameters: { type: "object", properties: { text: { type: "string" } }, required: ["text"] },
  handler: async ({ text }) => `Echo: ${text}`,
});

app.all("/api/copilot", copilotRuntimeNodeHttpEndpoint({ runtime }));
app.listen(4000, () => console.log("✅ Copilot Runtime at http://localhost:4000/api/copilot"));