#!/usr/bin/env python3
"""
ingest_milvus_v3_ollama_bm25_crf_intpk.py

- PK = INT64
- PK value = <CRF_INTEGER><sequence>  (no underscore)
  e.g. CRF=1001 → 10011, 10012, 10013 ...
- CRF value is read from the CSV row where question_label == "crf"
  or Prop == "crf" (case-insensitive)
- dense: Ollama bge-m3
- sparse: rank-bm25 over schema text
- value_vec: Ollama for short/non-JSON values
- insert: **one row at a time** (to avoid shape issues)
"""

import os
import csv
import json
import argparse
import requests
from typing import Dict, Any, List

from pymilvus import MilvusClient, DataType
from rank_bm25 import BM25Okapi

# -------- CONFIG --------
MILVUS_URI = os.environ.get("MILVUS_URI", "http://localhost:19530")
MILVUS_TOKEN = os.environ.get("MILVUS_TOKEN", "root:Milvus")
COLLECTION = os.environ.get("MILVUS_COLLECTION", "forms_hybrid_v3")

BGE_DIM = 1024
DEFAULT_STATUS = "active"

OLLAMA_URL = os.environ.get("OLLAMA_URL", "http://localhost:11434")
OLLAMA_MODEL = os.environ.get("OLLAMA_MODEL", "bge-m3")

BM25_MODEL_FILE = os.environ.get("BM25_MODEL_FILE", "bm25_model.json")


# -------- OLLAMA --------
def ollama_embed(text: str) -> List[float]:
    payload = {"model": OLLAMA_MODEL, "prompt": text}
    r = requests.post(f"{OLLAMA_URL}/api/embeddings", json=payload, timeout=25)
    r.raise_for_status()
    return r.json()["embedding"]


# -------- HELPERS --------
def normalize_value(val: str) -> str:
    return (val or "").strip().lower()


def is_json_like(val: str) -> bool:
    if not val:
        return False
    v = val.strip()
    return v.startswith("{") or v.startswith("[")


def build_schema_text(row: Dict[str, str]) -> str:
    ql = row.get("question_label") or row.get("Question_label") or ""
    prop = row.get("Prop") or ""
    sec = row.get("Section") or ""
    sub = row.get("Sub_section") or row.get("Subsection") or ""
    ptr = row.get("Json_pointer") or row.get("Json_Pointer") or ""

    parts = []
    if ql:
        parts.append(f"label: {ql}")
    if prop:
        parts.append(f"property: {prop}")
    if sec:
        parts.append(f"section: {sec}")
    if sub:
        parts.append(f"subsection: {sub}")
    if ptr:
        parts.append(f"pointer: {ptr}")
    return " ".join(parts)


def find_crf_int(rows: List[Dict[str, str]]) -> int:
    """
    Find CRF row and return its Value as int.
    You said: "crf value we will get from csv will be integers only" → so we cast to int.
    If not found or not int → fallback 1.
    """
    for r in rows:
        ql = (r.get("question_label") or r.get("Question_label") or "").strip().lower()
        prop = (r.get("Prop") or "").strip().lower()
        if ql == "crf" or prop == "crf":
            val = (r.get("Value") or "").strip()
            try:
                return int(val)
            except Exception:
                pass
    return 1  # safe fallback


# -------- COLLECTION --------
def ensure_collection(client: MilvusClient):
    # IMPORTANT:
    # if you previously created `forms_hybrid_v3` with VARCHAR PK,
    # drop it once and recreate with this schema.
    if client.has_collection(COLLECTION):
        return

    schema = client.create_schema(auto_id=False)

    # PK is now INT64 ✅
    schema.add_field("id", DataType.INT64, is_primary=True)

    schema.add_field("question_label", DataType.VARCHAR, max_length=256)
    schema.add_field("prop", DataType.VARCHAR, max_length=256)
    schema.add_field("value_text", DataType.VARCHAR, max_length=2048)
    schema.add_field("json_pointer", DataType.VARCHAR, max_length=512)
    schema.add_field("section", DataType.VARCHAR, max_length=256)
    schema.add_field("subsection", DataType.VARCHAR, max_length=256)
    schema.add_field("status", DataType.VARCHAR, max_length=64)

    schema.add_field("dense", DataType.FLOAT_VECTOR, dim=BGE_DIM)
    schema.add_field("sparse", DataType.SPARSE_FLOAT_VECTOR)
    schema.add_field("value_vec", DataType.FLOAT_VECTOR, dim=BGE_DIM)

    idx = client.prepare_index_params()
    idx.add_index("dense", "dense_idx", "AUTOINDEX", "COSINE")
    idx.add_index(
        "sparse",
        "sparse_idx",
        "SPARSE_INVERTED_INDEX",
        "IP",
        params={"inverted_index_algo": "DAAT_MAXSCORE"},
    )
    idx.add_index("value_vec", "value_vec_idx", "AUTOINDEX", "COSINE")

    client.create_collection(COLLECTION, schema=schema, index_params=idx)
    client.load_collection(COLLECTION)


# -------- INGEST --------
def ingest_csv(client: MilvusClient, csv_path: str):
    ensure_collection(client)

    # 1) read all rows
    rows: List[Dict[str, str]] = []
    schema_texts: List[str] = []
    with open(csv_path, "r", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        for r in reader:
            rows.append(r)
            schema_texts.append(build_schema_text(r))

    # 2) get CRF as integer
    crf_int = find_crf_int(rows)
    print(f"[i] Using CRF base: {crf_int} (from CSV)")

    # 3) build BM25 over all schema texts
    tokenized_docs = [txt.lower().split() for txt in schema_texts]
    bm25 = BM25Okapi(tokenized_docs)
    vocab = {tok: i for i, tok in enumerate(sorted({t for doc in tokenized_docs for t in doc}))}

    # 4) insert rows ONE BY ONE
    count = 0
    for seq, (row, doc_tokens, schema_text) in enumerate(
        zip(rows, tokenized_docs, schema_texts), start=1
    ):
        ql = row.get("question_label") or row.get("Question_label") or ""
        prop = row.get("Prop") or ""
        val = row.get("Value") or ""
        ptr = row.get("Json_pointer") or row.get("Json_Pointer") or ""
        sec = row.get("Section") or ""
        sub = row.get("Sub_section") or row.get("Subsection") or ""

        val_norm = normalize_value(val)

        # dense for schema
        schema_dense = ollama_embed(schema_text)

        # BM25 sparse for this doc
        doc_len = len(doc_tokens)
        avgdl = bm25.avgdl
        k1 = bm25.k1
        b = bm25.b

        tf_in_doc: Dict[str, int] = {}
        for tok in doc_tokens:
            tf_in_doc[tok] = tf_in_doc.get(tok, 0) + 1

        sparse_vec: Dict[int, float] = {}
        for tok, tf in tf_in_doc.items():
            if tok not in bm25.idf:
                continue
            idf = bm25.idf[tok]
            score = idf * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (doc_len / avgdl)))
            term_id = vocab[tok]
            sparse_vec[term_id] = float(score)

        # value_vec
        if val and not is_json_like(val) and len(val) < 120:
            value_dense = ollama_embed(val)
        else:
            value_dense = [0.0] * BGE_DIM

        # ✅ INT64 PK: concat crf_int and seq as string, then cast to int
        # crf_int = 1001, seq = 3 → "10013" → int("10013")
        pk_int = int(f"{crf_int}{seq}")

        one_row = {
            "id": pk_int,
            "question_label": ql,
            "prop": prop,
            "value_text": val_norm,
            "json_pointer": ptr,
            "section": sec,
            "subsection": sub,
            "status": DEFAULT_STATUS,
            "dense": schema_dense,
            "sparse": sparse_vec,
            "value_vec": value_dense,
        }

        client.insert(COLLECTION, [one_row])
        count += 1

        if count % 100 == 0:
            client.flush(COLLECTION)
            print(f"[i] Inserted {count} rows...")

    client.flush(COLLECTION)
    print(f"[OK] Inserted {count} rows from {csv_path} into {COLLECTION}")

    # 5) save BM25 model
    bm25_state = {
        "k1": bm25.k1,
        "b": bm25.b,
        "avgdl": bm25.avgdl,
        "idf": bm25.idf,
        "vocab": vocab,
    }
    with open(BM25_MODEL_FILE, "w", encoding="utf-8") as f:
        json.dump(bm25_state, f, ensure_ascii=False, indent=2)
    print(f"[OK] Saved BM25 model to {BM25_MODEL_FILE}")


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--csv", required=True, help="CSV file to ingest")
    args = ap.parse_args()

    client = MilvusClient(uri=MILVUS_URI, token=MILVUS_TOKEN)
    ingest_csv(client, args.csv)


if __name__ == "__main__":
    main()