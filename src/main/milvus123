#!/usr/bin/env python3
"""
ingest_milvus_v3_ollama_bm25_crfpk.py

Ingest CSV into Milvus with:
- PK = string, built as "<CRF_VALUE>_<row_number>"
- dense: from Ollama bge-m3
- sparse: from rank-bm25
- value_vec: from Ollama (for short/non-JSON values)
- BM25 model saved to bm25_model.json

Run:
    python ingest_milvus_v3_ollama_bm25_crfpk.py --csv ./forms.csv
"""

import os
import csv
import json
import argparse
import requests
from typing import Dict, Any, List

from pymilvus import MilvusClient, DataType
from rank_bm25 import BM25Okapi

# ---------- CONFIG ----------
MILVUS_URI = os.environ.get("MILVUS_URI", "http://localhost:19530")
MILVUS_TOKEN = os.environ.get("MILVUS_TOKEN", "root:Milvus")
COLLECTION = os.environ.get("MILVUS_COLLECTION", "forms_hybrid_v3")
BGE_DIM = 1024
DEFAULT_STATUS = "active"

OLLAMA_URL = os.environ.get("OLLAMA_URL", "http://localhost:11434")
OLLAMA_MODEL = os.environ.get("OLLAMA_MODEL", "bge-m3")

BM25_MODEL_FILE = os.environ.get("BM25_MODEL_FILE", "bm25_model.json")


# ---------- OLLAMA EMBEDDING ----------
def ollama_embed(text: str) -> List[float]:
    payload = {"model": OLLAMA_MODEL, "prompt": text}
    resp = requests.post(f"{OLLAMA_URL}/api/embeddings", json=payload, timeout=25)
    resp.raise_for_status()
    return resp.json()["embedding"]


# ---------- HELPERS ----------
def normalize_value(val: str) -> str:
    return (val or "").strip().lower()


def is_json_like(val: str) -> bool:
    if not val:
        return False
    v = val.strip()
    return v.startswith("{") or v.startswith("[")


def build_schema_text(row: Dict[str, str]) -> str:
    ql = row.get("question_label") or row.get("Question_label") or ""
    prop = row.get("Prop") or ""
    sec = row.get("Section") or ""
    sub = row.get("Sub_section") or row.get("Subsection") or ""
    ptr = row.get("Json_pointer") or row.get("Json_Pointer") or ""

    parts = []
    if ql:
        parts.append(f"label: {ql}")
    if prop:
        parts.append(f"property: {prop}")
    if sec:
        parts.append(f"section: {sec}")
    if sub:
        parts.append(f"subsection: {sub}")
    if ptr:
        parts.append(f"pointer: {ptr}")
    return " ".join(parts)


def find_crf_value(rows: List[Dict[str, str]]) -> str:
    """
    Look for a row where question_label == 'crf' or prop == 'crf' (case-insensitive)
    and return its Value.
    If not found, return 'CRF'.
    """
    for r in rows:
        ql = (r.get("question_label") or r.get("Question_label") or "").strip().lower()
        prop = (r.get("Prop") or "").strip().lower()
        if ql == "crf" or prop == "crf":
            val = (r.get("Value") or "").strip()
            if val:
                return val
    return "CRF"


# ---------- COLLECTION ----------
def ensure_collection(client: MilvusClient):
    # we are changing PK to VARCHAR
    if client.has_collection(COLLECTION):
        return

    schema = client.create_schema(auto_id=False)

    # <-- PK is now VARCHAR
    schema.add_field("id", DataType.VARCHAR, is_primary=True, max_length=128)

    schema.add_field("question_label", DataType.VARCHAR, max_length=256)
    schema.add_field("prop", DataType.VARCHAR, max_length=256)
    schema.add_field("value_text", DataType.VARCHAR, max_length=2048)
    schema.add_field("json_pointer", DataType.VARCHAR, max_length=512)
    schema.add_field("section", DataType.VARCHAR, max_length=256)
    schema.add_field("subsection", DataType.VARCHAR, max_length=256)
    schema.add_field("status", DataType.VARCHAR, max_length=64)

    # vectors
    schema.add_field("dense", DataType.FLOAT_VECTOR, dim=BGE_DIM)
    schema.add_field("sparse", DataType.SPARSE_FLOAT_VECTOR)
    schema.add_field("value_vec", DataType.FLOAT_VECTOR, dim=BGE_DIM)

    index_params = client.prepare_index_params()
    index_params.add_index(
        field_name="dense",
        index_name="dense_idx",
        index_type="AUTOINDEX",
        metric_type="COSINE",
    )
    index_params.add_index(
        field_name="sparse",
        index_name="sparse_idx",
        index_type="SPARSE_INVERTED_INDEX",
        metric_type="IP",
        params={"inverted_index_algo": "DAAT_MAXSCORE"},
    )
    index_params.add_index(
        field_name="value_vec",
        index_name="value_vec_idx",
        index_type="AUTOINDEX",
        metric_type="COSINE",
    )

    client.create_collection(
        collection_name=COLLECTION,
        schema=schema,
        index_params=index_params,
    )
    client.load_collection(COLLECTION)


# ---------- INGEST ----------
def ingest_csv(client: MilvusClient, csv_path: str):
    ensure_collection(client)

    # 1) read all rows first
    rows: List[Dict[str, str]] = []
    schema_texts: List[str] = []
    with open(csv_path, "r", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        for r in reader:
            rows.append(r)
            schema_texts.append(build_schema_text(r))

    # 2) find CRF value from this CSV
    crf_val = find_crf_value(rows).strip()
    if not crf_val:
        crf_val = "CRF"
    # normalize a bit (optional)
    crf_val = crf_val.replace(" ", "_")

    # 3) build BM25 on ALL schema texts
    tokenized_docs = [txt.lower().split() for txt in schema_texts]
    bm25 = BM25Okapi(tokenized_docs)
    vocab = {tok: i for i, tok in enumerate(sorted({t for doc in tokenized_docs for t in doc}))}

    # 4) prepare buffer
    buf = {
        "id": [],
        "question_label": [],
        "prop": [],
        "value_text": [],
        "json_pointer": [],
        "section": [],
        "subsection": [],
        "status": [],
        "dense": [],
        "sparse": [],
        "value_vec": [],
    }

    # 5) fill buffer
    row_seq = 1
    for row, doc_tokens, schema_text in zip(rows, tokenized_docs, schema_texts):
        ql = row.get("question_label") or row.get("Question_label") or ""
        prop = row.get("Prop") or ""
        val = row.get("Value") or ""
        ptr = row.get("Json_pointer") or row.get("Json_Pointer") or ""
        sec = row.get("Section") or ""
        sub = row.get("Sub_section") or row.get("Subsection") or ""

        val_norm = normalize_value(val)

        # --- schema dense from Ollama
        schema_dense = ollama_embed(schema_text)

        # --- BM25 sparse for this doc
        doc_len = len(doc_tokens)
        avgdl = bm25.avgdl
        k1 = bm25.k1
        b = bm25.b

        tf_in_doc = {}
        for tok in doc_tokens:
            tf_in_doc[tok] = tf_in_doc.get(tok, 0) + 1

        sparse_vec: Dict[int, float] = {}
        for tok, tf in tf_in_doc.items():
            if tok not in bm25.idf:
                continue
            idf = bm25.idf[tok]
            score = idf * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (doc_len / avgdl)))
            term_id = vocab[tok]
            sparse_vec[term_id] = float(score)

        # --- value dense (optional)
        if val and not is_json_like(val) and len(val) < 120:
            value_dense = ollama_embed(val)
        else:
            value_dense = [0.0] * BGE_DIM

        # --- PRIMARY KEY (string): "<crf>_<seq>"
        pk_str = f"{crf_val}_{row_seq}"

        buf["id"].append(pk_str)          # ðŸ‘ˆ now string, no int64 errors
        buf["question_label"].append(ql)
        buf["prop"].append(prop)
        buf["value_text"].append(val_norm)
        buf["json_pointer"].append(ptr)
        buf["section"].append(sec)
        buf["subsection"].append(sub)
        buf["status"].append(DEFAULT_STATUS)
        buf["dense"].append(schema_dense)
        buf["sparse"].append(sparse_vec)
        buf["value_vec"].append(value_dense)

        row_seq += 1

    # 6) debug shapes
    print("[debug] column shapes before insert:")
    for k, v in buf.items():
        if not v:
            print(f"  {k}: EMPTY")
        else:
            print(f"  {k}: len={len(v)}, first_type={type(v[0])}")

    # 7) insert
    client.insert(COLLECTION, buf)
    client.flush(COLLECTION)
    print(f"[OK] Inserted {len(buf['id'])} rows from {csv_path} into {COLLECTION}")
    print(f"[OK] Used CRF prefix: {crf_val}")

    # 8) save BM25 model
    bm25_state = {
        "k1": bm25.k1,
        "b": bm25.b,
        "avgdl": bm25.avgdl,
        "idf": bm25.idf,
        "vocab": vocab,
    }
    with open(BM25_MODEL_FILE, "w", encoding="utf-8") as f:
        json.dump(bm25_state, f, ensure_ascii=False, indent=2)
    print(f"[OK] Saved BM25 model to {BM25_MODEL_FILE}")


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--csv", required=True, help="CSV file to ingest")
    args = ap.parse_args()

    client = MilvusClient(uri=MILVUS_URI, token=MILVUS_TOKEN)
    ingest_csv(client, args.csv)


if __name__ == "__main__":
    main()