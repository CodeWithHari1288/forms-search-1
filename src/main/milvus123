#!/usr/bin/env python3
"""
ingest_milvus_v3_ollama.py

Ingest CSV -> Milvus with 3 vector legs, using **Ollama bge-m3** for dense.

Requires:
    - Milvus running (http://localhost:19530 by default)
    - Ollama running (http://localhost:11434) with model "bge-m3"
      Run first:  ollama pull bge-m3

CSV columns (case-insensitive):
    question_label, Prop, Value, Json_pointer, Section, Sub_section
"""

import os
import csv
import argparse
import requests
from typing import Dict, Any, List

from pymilvus import (
    MilvusClient,
    DataType,
)

# ---------------- CONFIG ----------------
MILVUS_URI = os.environ.get("MILVUS_URI", "http://localhost:19530")
MILVUS_TOKEN = os.environ.get("MILVUS_TOKEN", "root:Milvus")
COLLECTION = os.environ.get("MILVUS_COLLECTION", "forms_hybrid_v3")
BGE_DIM = 1024
DEFAULT_STATUS = "active"
OLLAMA_URL = os.environ.get("OLLAMA_URL", "http://localhost:11434")
OLLAMA_MODEL = os.environ.get("OLLAMA_MODEL", "bge-m3")


# ---------------- OLLAMA EMBEDDING ----------------
def ollama_embed(text: str) -> List[float]:
    """
    Call Ollama /api/embeddings to get a dense vector.
    Assumes Ollama model returns 1024 dims (bge-m3 does).
    """
    payload = {
        "model": OLLAMA_MODEL,
        "prompt": text,
    }
    resp = requests.post(f"{OLLAMA_URL}/api/embeddings", json=payload, timeout=20)
    resp.raise_for_status()
    data = resp.json()
    # Ollama returns: {"embedding": [..]}
    return data["embedding"]


# ---------------- SIMPLE SPARSE BUILDER ----------------
def text_to_sparse(text: str) -> Dict[int, float]:
    """
    Since Ollama embeddings are dense-only, we create a simple sparse
    vector ourselves:
      - lowercase
      - split on spaces
      - for each token -> hash -> positive id -> weight = 1.0
    This is not as good as real BGE-M3 lexical weights, but lets us store
    something in Milvus SPARSE_FLOAT_VECTOR.
    """
    sparse: Dict[int, float] = {}
    if not text:
        return sparse
    tokens = text.lower().replace(";", " ").replace(":", " ").split()
    for tok in tokens:
        if not tok:
            continue
        # stable-ish id: take hash & 0x7fffffff
        tid = abs(hash(tok)) % 1000000  # keep in a range
        # you can increment weight if repeat
        sparse[tid] = sparse.get(tid, 0.0) + 1.0
    return sparse


# ---------------- COLLECTION ----------------
def ensure_collection(client: MilvusClient):
    if client.has_collection(COLLECTION):
        return

    schema = client.create_schema(auto_id=False)

    schema.add_field("id", DataType.INT64, is_primary=True)
    schema.add_field("question_label", DataType.VARCHAR, max_length=256)
    schema.add_field("prop", DataType.VARCHAR, max_length=256)
    schema.add_field("value_text", DataType.VARCHAR, max_length=2048)
    schema.add_field("json_pointer", DataType.VARCHAR, max_length=512)
    schema.add_field("section", DataType.VARCHAR, max_length=256)
    schema.add_field("subsection", DataType.VARCHAR, max_length=256)
    schema.add_field("status", DataType.VARCHAR, max_length=64)

    # 3 vector legs
    schema.add_field("dense", DataType.FLOAT_VECTOR, dim=BGE_DIM)      # schema dense
    schema.add_field("sparse", DataType.SPARSE_FLOAT_VECTOR)           # schema sparse
    schema.add_field("value_vec", DataType.FLOAT_VECTOR, dim=BGE_DIM)  # value dense

    index_params = client.prepare_index_params()
    index_params.add_index(
        field_name="dense",
        index_name="dense_idx",
        index_type="AUTOINDEX",
        metric_type="COSINE",
    )
    index_params.add_index(
        field_name="sparse",
        index_name="sparse_idx",
        index_type="SPARSE_INVERTED_INDEX",
        metric_type="IP",
        params={"inverted_index_algo": "DAAT_MAXSCORE"},
    )
    index_params.add_index(
        field_name="value_vec",
        index_name="value_vec_idx",
        index_type="AUTOINDEX",
        metric_type="COSINE",
    )

    client.create_collection(
        collection_name=COLLECTION,
        schema=schema,
        index_params=index_params,
    )
    client.load_collection(COLLECTION)


# ---------------- HELPERS ----------------
def normalize_value(val: str) -> str:
    return (val or "").strip().lower()


def is_json_like(val: str) -> bool:
    if not val:
        return False
    v = val.strip()
    return v.startswith("{") or v.startswith("[")


def build_schema_text(row: Dict[str, str]) -> str:
    ql = row.get("question_label") or row.get("Question_label") or ""
    prop = row.get("Prop") or ""
    sec = row.get("Section") or ""
    sub = row.get("Sub_section") or row.get("Subsection") or ""
    ptr = row.get("Json_pointer") or row.get("Json_Pointer") or ""

    parts = []
    if ql:
        parts.append(f"label: {ql}")
    if prop:
        parts.append(f"property: {prop}")
    if sec:
        parts.append(f"section: {sec}")
    if sub:
        parts.append(f"subsection: {sub}")
    if ptr:
        parts.append(f"pointer: {ptr}")
    return " ; ".join(parts)


# ---------------- INGEST ----------------
def ingest_csv(client: MilvusClient, csv_path: str):
    ensure_collection(client)

    buf = {
        "id": [],
        "question_label": [],
        "prop": [],
        "value_text": [],
        "json_pointer": [],
        "section": [],
        "subsection": [],
        "status": [],
        "dense": [],
        "sparse": [],
        "value_vec": [],
    }

    pk = 1
    with open(csv_path, "r", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        for row in reader:
            ql = row.get("question_label") or row.get("Question_label") or ""
            prop = row.get("Prop") or ""
            val = row.get("Value") or ""
            ptr = row.get("Json_pointer") or row.get("Json_Pointer") or ""
            sec = row.get("Section") or ""
            sub = row.get("Sub_section") or row.get("Subsection") or ""

            val_norm = normalize_value(val)

            # 1) schema text
            schema_text = build_schema_text(row)
            # 1a) dense from Ollama
            schema_dense = ollama_embed(schema_text)
            # 1b) sparse from our tokenizer
            schema_sparse = text_to_sparse(schema_text)

            # 2) value dense (only if small and not JSON)
            if val and not is_json_like(val) and len(val) < 120:
                value_dense = ollama_embed(val)
            else:
                value_dense = [0.0] * BGE_DIM

            buf["id"].append(pk)
            buf["question_label"].append(ql)
            buf["prop"].append(prop)
            buf["value_text"].append(val_norm)
            buf["json_pointer"].append(ptr)
            buf["section"].append(sec)
            buf["subsection"].append(sub)
            buf["status"].append(DEFAULT_STATUS)
            buf["dense"].append(schema_dense)
            buf["sparse"].append(schema_sparse)
            buf["value_vec"].append(value_dense)

            pk += 1

    client.insert(COLLECTION, buf)
    client.flush(COLLECTION)
    print(f"[OK] Inserted {len(buf['id'])} rows into {COLLECTION}")


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--csv", required=True, help="CSV file to ingest")
    args = ap.parse_args()

    client = MilvusClient(uri=MILVUS_URI, token=MILVUS_TOKEN)
    ingest_csv(client, args.csv)


if __name__ == "__main__":
    main()









#!/usr/bin/env python3
"""
retrieve_milvus_v3_ollama.py

3-leg hybrid search using:
  - schema dense (Ollama bge-m3)
  - schema sparse (our text->sparse hasher)
  - value dense (Ollama bge-m3)

Supports filters:
  --section
  --subsection
  --status
  --value   (exact normalized value_text)

Usage:
    python retrieve_milvus_v3_ollama.py --query "address" --section "Address"
    python retrieve_milvus_v3_ollama.py --query "address hyderbad"
    python retrieve_milvus_v3_ollama.py --query "address" --section "Address" --value "hyderabad"
"""

import os
import argparse
import requests
from typing import Dict, Any, List

from pymilvus import (
    MilvusClient,
    AnnSearchRequest,
    WeightedRanker,
)

MILVUS_URI = os.environ.get("MILVUS_URI", "http://localhost:19530")
MILVUS_TOKEN = os.environ.get("MILVUS_TOKEN", "root:Milvus")
COLLECTION = os.environ.get("MILVUS_COLLECTION", "forms_hybrid_v3")
BGE_DIM = 1024
OLLAMA_URL = os.environ.get("OLLAMA_URL", "http://localhost:11434")
OLLAMA_MODEL = os.environ.get("OLLAMA_MODEL", "bge-m3")


def ollama_embed(text: str) -> List[float]:
    payload = {
        "model": OLLAMA_MODEL,
        "prompt": text,
    }
    resp = requests.post(f"{OLLAMA_URL}/api/embeddings", json=payload, timeout=20)
    resp.raise_for_status()
    return resp.json()["embedding"]


def text_to_sparse(text: str) -> Dict[int, float]:
    sparse: Dict[int, float] = {}
    if not text:
        return sparse
    tokens = text.lower().replace(";", " ").replace(":", " ").split()
    for tok in tokens:
        if not tok:
            continue
        tid = abs(hash(tok)) % 1000000
        sparse[tid] = sparse.get(tid, 0.0) + 1.0
    return sparse


def build_expr(section: str, subsection: str, status: str, value_text: str) -> str:
    clauses = []
    if section:
        clauses.append(f'section == "{section}"')
    if subsection:
        clauses.append(f'subsection == "{subsection}"')
    if status:
        clauses.append(f'status == "{status}"')
    if value_text:
        v = value_text.strip().lower()
        clauses.append(f'value_text == "{v}"')
    return " and ".join(clauses)


def run_hybrid_3leg(
    client: MilvusClient,
    query_text: str,
    section: str = "",
    subsection: str = "",
    status: str = "active",
    value_text: str = "",
    topk: int = 10,
):
    # 1) schema dense from Ollama
    q_schema_dense = ollama_embed(query_text)
    # 2) schema sparse from our tokenizer
    q_schema_sparse = text_to_sparse(query_text)
    # 3) value dense (we reuse the same text; in real code you might extract the value token)
    q_value_dense = ollama_embed(query_text)

    expr = build_expr(section, subsection, status, value_text)

    req_schema_dense = AnnSearchRequest(
        data=[q_schema_dense],
        anns_field="dense",
        limit=topk,
        param={"metric_type": "COSINE", "params": {}},
        expr=expr if expr else None,
    )

    req_schema_sparse = AnnSearchRequest(
        data=[q_schema_sparse],
        anns_field="sparse",
        limit=topk,
        param={
            "metric_type": "IP",
            "params": {"drop_ratio_search": 0.2},
        },
        expr=expr if expr else None,
    )

    req_value_dense = AnnSearchRequest(
        data=[q_value_dense],
        anns_field="value_vec",
        limit=topk,
        param={"metric_type": "COSINE", "params": {}},
        expr=expr if expr else None,
    )

    # weights: tune later
    ranker = WeightedRanker(0.5, 0.3, 0.2)

    res = client.hybrid_search(
        collection_name=COLLECTION,
        reqs=[req_schema_dense, req_schema_sparse, req_value_dense],
        ranker=ranker,
        limit=topk,
        output_fields=[
            "question_label",
            "prop",
            "value_text",
            "json_pointer",
            "section",
            "subsection",
            "status",
        ],
    )

    return res


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--query", required=True, help="NL query, ex: 'address hyderabad'")
    ap.add_argument("--section", default="", help="Filter: section")
    ap.add_argument("--subsection", default="", help="Filter: subsection")
    ap.add_argument("--status", default="active", help="Filter: status")
    ap.add_argument("--value", default="", help="Filter: exact normalized value_text")
    ap.add_argument("--topk", type=int, default=10, help="Top-k")
    args = ap.parse_args()

    client = MilvusClient(uri=MILVUS_URI, token=MILVUS_TOKEN)

    results = run_hybrid_3leg(
        client,
        query_text=args.query,
        section=args.section,
        subsection=args.subsection,
        status=args.status,
        value_text=args.value,
        topk=args.topk,
    )

    for hits in results:
        for rank, h in enumerate(hits, start=1):
            print("--------------------------------------------------")
            print(f"rank: {rank}")
            print(f"id: {h.id}")
            print(f"distance (fused): {h.distance}")
            print(f"label: {h.get('question_label')}")
            print(f"prop: {h.get('prop')}")
            print(f"value_text: {h.get('value_text')}")
            print(f"json_pointer: {h.get('json_pointer')}")
            print(f"section: {h.get('section')} | subsection: {h.get('subsection')}")
            print(f"status: {h.get('status')}")


if __name__ == "__main__":
    main()




