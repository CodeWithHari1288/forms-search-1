#!/usr/bin/env python3
"""
Ingest a schema-only collection for rewrite/query understanding in LangGraph.

Collection: form_schema_index

Fields:
  - id (INT64, auto_id primary key)
  - Question_label   (VARCHAR)
  - Prop             (VARCHAR)
  - Section          (VARCHAR)
  - Subsection       (VARCHAR)
  - dense            (FLOAT_VECTOR, 1024)  <-- from BGE-M3 via Ollama

No Value / Json_pointer / Question_context here.
This is ONLY for mapping user NLP â†’ schema fields in your rewrite node.
"""

import os
import glob
from typing import List, Dict, Any

import pandas as pd
import requests
from pymilvus import (
    MilvusClient,
    DataType,
    FieldSchema,
    CollectionSchema,
)

# ----------------------------
# CONFIG
# ----------------------------
MILVUS_URI = "http://localhost:19530"   # Milvus standalone
CSV_DIR = "./csvs"                      # folder containing your CSV files
SCHEMA_COLLECTION = "form_schema_index"

# BGE-M3 dense dimension
DENSE_DIM = 1024

# Batch insert size
BATCH_SIZE = 100

# Ollama config
OLLAMA_URL = "http://localhost:11434/api/embeddings"
OLLAMA_MODEL = "bge-m3"

# CSV headers we expect (we only use some of them)
REQUIRED_COLS = [
    "Question_label",
    "Prop",
    "Value",
    "Json_pointer",
    "Question_context",
    "Section",
    "Subsection",
]


# ----------------------------
# CONNECT TO MILVUS
# ----------------------------
client = MilvusClient(uri=MILVUS_URI)


# ----------------------------
# COLLECTION DEFINITION
# ----------------------------
def ensure_schema_collection():
    if client.has_collection(SCHEMA_COLLECTION):
        print(f"âœ… Collection '{SCHEMA_COLLECTION}' already exists.")
        return

    fields = [
        FieldSchema(
            name="id",
            dtype=DataType.INT64,
            is_primary=True,
            auto_id=True,
        ),
        FieldSchema(
            name="Question_label",
            dtype=DataType.VARCHAR,
            max_length=512,
        ),
        FieldSchema(
            name="Prop",
            dtype=DataType.VARCHAR,
            max_length=256,
        ),
        FieldSchema(
            name="Section",
            dtype=DataType.VARCHAR,
            max_length=256,
        ),
        FieldSchema(
            name="Subsection",
            dtype=DataType.VARCHAR,
            max_length=256,
        ),
        FieldSchema(
            name="dense",
            dtype=DataType.FLOAT_VECTOR,
            dim=DENSE_DIM,
        ),
    ]

    schema = CollectionSchema(
        fields=fields,
        description="Schema-only collection (dense BGE-M3) for query rewrite",
    )

    client.create_collection(
        collection_name=SCHEMA_COLLECTION,
        schema=schema,
    )
    print(f"ðŸ†• Created collection '{SCHEMA_COLLECTION}'.")

    # Create index on dense vector
    print("ðŸ“¦ Creating HNSW index on 'dense' ...")
    client.create_index(
        collection_name=SCHEMA_COLLECTION,
        field_name="dense",
        index_params={
            "index_type": "HNSW",
            "metric_type": "COSINE",
            "params": {"M": 16, "efConstruction": 64},
        },
    )

    client.load_collection(SCHEMA_COLLECTION)
    print("âœ… Index created and collection loaded.")


# ----------------------------
# OLLAMA EMBEDDINGS (BGE-M3)
# ----------------------------
def get_bgem3_embedding(text: str):
    """
    Call Ollama /api/embeddings for BGE-M3 and return a 1024-dim vector.
    """
    resp = requests.post(
        OLLAMA_URL,
        json={
            "model": OLLAMA_MODEL,
            "prompt": text,
        },
        timeout=120,
    )
    resp.raise_for_status()
    data = resp.json()

    # Ollama returns: {"embedding": [...], ...}
    emb = data.get("embedding")
    if emb is None:
        raise RuntimeError(f"No 'embedding' field in Ollama response: {data}")

    if len(emb) != DENSE_DIM:
        print(f"âš ï¸ Warning: expected dim {DENSE_DIM}, got {len(emb)}")

    return emb


def embed_schema_text(label: str, prop: str, section: str, subsection: str):
    """
    Build the schema text to embed.

    You can adjust this prompt style anytime:
      e.g., include more hints like "field label", "property name", etc.
    """
    parts = [label, f"({prop})"]
    if section:
        parts.append(f"section: {section}")
    if subsection:
        parts.append(f"subsection: {subsection}")
    text = " - ".join(parts)

    return get_bgem3_embedding(text)


# ----------------------------
# INGESTION
# ----------------------------
def ingest_csv_folder(folder: str):
    csv_files = glob.glob(os.path.join(folder, "*.csv"))
    if not csv_files:
        print(f"âŒ No CSV files found in {folder}")
        return

    ensure_schema_collection()

    for path in csv_files:
        print(f"ðŸ“„ Reading {os.path.basename(path)} ...")
        df = pd.read_csv(path)

        missing = [c for c in REQUIRED_COLS if c not in df.columns]
        if missing:
            print(f"âš ï¸ Missing columns {missing} in {path}, skipping.")
            continue

        ingest_df(df)


def ingest_df(df: pd.DataFrame):
    batch: List[Dict[str, Any]] = []

    for _, row in df.iterrows():
        q_label = str(row["Question_label"])
        prop = str(row["Prop"])
        section = "" if pd.isna(row["Section"]) else str(row["Section"])
        subsection = "" if pd.isna(row["Subsection"]) else str(row["Subsection"])

        dense_vec = embed_schema_text(q_label, prop, section, subsection)

        record = {
            "Question_label": q_label,
            "Prop": prop,
            "Section": section,
            "Subsection": subsection,
            "dense": dense_vec,
        }
        batch.append(record)

        if len(batch) >= BATCH_SIZE:
            flush_batch(batch)

    if batch:
        flush_batch(batch)


def flush_batch(batch: List[Dict[str, Any]]):
    print(f"â¬†ï¸ Inserting batch of {len(batch)} rows into '{SCHEMA_COLLECTION}' ...")
    client.insert(collection_name=SCHEMA_COLLECTION, data=batch)
    print("âœ… Batch inserted.")


# ----------------------------
# MAIN
# ----------------------------
if __name__ == "__main__":
    ingest_csv_folder(CSV_DIR)
    print("ðŸŽ‰ Finished ingesting schema collection with dense BGE-M3 embeddings.")











# rewrite_query_bgem3.py

from typing import List, Dict, Any
from typing_extensions import TypedDict
import os
import json

from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

from pymilvus import MilvusClient
from FlagEmbedding import BGEM3FlagModel

# -------------------------
# CONFIG
# -------------------------
MILVUS_URI = os.getenv("MILVUS_URI", "http://localhost:19530")
SCHEMA_COLLECTION = os.getenv("SCHEMA_COLLECTION", "form_schema_index")

DENSE_DIM = 1024
TOP_K_SCHEMA = 8   # how many schema fields to show LLM

# -------------------------
# LANGGRAPH STATE
# -------------------------
class RewriteState(TypedDict):
    # Input
    user_query: str

    # Outputs
    schema_hits: List[Dict[str, Any]]
    structured_query: Dict[str, Any]


# -------------------------
# MILVUS CLIENT
# -------------------------
client = MilvusClient(uri=MILVUS_URI)


# -------------------------
# BGEM3 FLAG MODEL
# -------------------------
# Same model you used in ingest (BAAI/bge-m3)
print("Loading BGE-M3 FlagEmbedding model for rewrite...")
embed_model = BGEM3FlagModel("BAAI/bge-m3", use_fp16=True)


def get_bgem3_embedding(text: str) -> List[float]:
    """
    Use BGEM3FlagModel to get a dense 1024-d embedding.
    We only use dense here (no sparse) for schema rewrite collection.
    """
    out = embed_model.encode(
        text,
        return_dense=True,
        return_sparse=False,
        normalize_embeddings=True,
    )
    vec = out["dense_vecs"][0]
    if len(vec) != DENSE_DIM:
        print(f"âš ï¸ BGEM3 dim mismatch: expected {DENSE_DIM}, got {len(vec)}")
    return vec


def search_schema_in_milvus(query: str, k: int = TOP_K_SCHEMA) -> List[Dict[str, Any]]:
    """
    Vector search against form_schema_index using BGE-M3 embedding.
    Returns a list[dict] with label/prop/section/subsection + score.
    """
    q_vec = get_bgem3_embedding(query)

    res = client.search(
        collection_name=SCHEMA_COLLECTION,
        data=[q_vec],
        anns_field="dense",
        limit=k,
        output_fields=["Question_label", "Prop", "Section", "Subsection"],
        search_params={
            "metric_type": "COSINE",
            "params": {},
        },
    )

    hits: List[Dict[str, Any]] = []
    if not res:
        return hits

    for hit in res[0]:
        entity = hit.get("entity", {})
        hits.append(
            {
                "id": hit.get("id"),
                "score": hit.get("distance"),
                "Question_label": entity.get("Question_label", ""),
                "Prop": entity.get("Prop", ""),
                "Section": entity.get("Section", ""),
                "Subsection": entity.get("Subsection", ""),
            }
        )
    return hits


# -------------------------
# LLM FOR REWRITE
# -------------------------
# Swap this to your own LLM if needed (OpenAI, local, etc.)
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0,
)


def build_rewrite_prompt(
    user_query: str,
    schema_hits: List[Dict[str, Any]],
) -> List[Any]:
    """
    Build messages to instruct the LLM to produce a structured JSON query.
    """
    lines = []
    for i, f in enumerate(schema_hits, start=1):
        lines.append(
            f"{i}. label={f['Question_label']} | prop={f['Prop']} "
            f"| section={f['Section']} | subsection={f['Subsection']} "
            f"(score={round(f['score'], 4) if f['score'] is not None else 'NA'})"
        )
    fields_text = "\n".join(lines) if lines else "(no schema hits)"

    system = SystemMessage(
        content=(
            "You are a query rewriting assistant for a forms database.\n"
            "You are given:\n"
            "1) A natural language user query.\n"
            "2) A list of candidate fields (label, prop, section, subsection).\n\n"
            "Your job:\n"
            "- Choose which fields are relevant to the user query.\n"
            "- Produce a STRICT JSON object (no extra text) describing "
            "a structured query the backend can use.\n\n"
            "Output JSON format:\n"
            "{\n"
            '  "filters": [\n'
            '    {"prop": string, "section": string, "subsection": string},\n'
            "    ...\n"
            "  ],\n"
            '  "original_query": string,\n'
            '  "rewrite": string\n'
            "}\n\n"
            "- If a field is relevant but section/subsection is empty, set them to \"\".\n"
            "- If nothing matches, return filters: [].\n"
            "- Do NOT include comments or explanation. Only raw JSON."
        )
    )

    human = HumanMessage(
        content=(
            f"User query:\n{user_query}\n\n"
            f"Candidate fields:\n{fields_text}\n\n"
            "Now return ONLY the JSON object in the required format."
        )
    )

    return [system, human]


# -------------------------
# LANGGRAPH NODE
# -------------------------
def rewrite_query_node(state: RewriteState) -> Dict[str, Any]:
    """
    Node:
      input : state['user_query']
      output: state['schema_hits'], state['structured_query']
    """
    user_query = state["user_query"]

    # 1) Vector search on schema collection using bgem3
    schema_hits = search_schema_in_milvus(user_query, k=TOP_K_SCHEMA)

    # 2) LLM rewrite â†’ structured query JSON
    messages = build_rewrite_prompt(user_query, schema_hits)
    raw = llm.invoke(messages)
    txt = raw.content.strip()

    try:
        structured = json.loads(txt)
    except json.JSONDecodeError:
        # crude fallback if the model adds extra text
        start = txt.find("{")
        end = txt.rfind("}")
        if start != -1 and end != -1 and end > start:
            try:
                structured = json.loads(txt[start : end + 1])
            except json.JSONDecodeError:
                structured = {"error": "LLM did not return valid JSON", "raw": txt}
        else:
            structured = {"error": "LLM did not return JSON", "raw": txt}

    return {
        "schema_hits": schema_hits,
        "structured_query": structured,
    }


# -------------------------
# BUILD GRAPH
# -------------------------
builder = StateGraph(RewriteState)

builder.add_node("rewrite_query", rewrite_query_node)
builder.add_edge(START, "rewrite_query")
builder.add_edge("rewrite_query", END)

rewrite_graph = builder.compile()


if __name__ == "__main__":
    # quick test
    test_state = {"user_query": "Get all PAN and GSTIN fields for billing address"}
    result = rewrite_graph.invoke(test_state)

    from pprint import pprint
    print("\n=== Schema hits ===")
    pprint(result["schema_hits"])
    print("\n=== Structured query ===")
    pprint(result["structured_query"])












# rewrite_query_bgem3_only.py
"""
LangGraph node for query rewrite using only:
- BGEM3FlagModel (BAAI/bge-m3) for embeddings
- Milvus for schema search

No GPT / OpenAI / LLM.

Collection used: form_schema_index
Fields expected in that collection:
  - Question_label (VARCHAR)
  - Prop           (VARCHAR)
  - Section        (VARCHAR)
  - Subsection     (VARCHAR)
  - dense          (FLOAT_VECTOR, 1024)
"""

from typing import List, Dict, Any
from typing_extensions import TypedDict
import os

from langgraph.graph import StateGraph, START, END

from pymilvus import MilvusClient
from FlagEmbedding import BGEM3FlagModel


# -------------------------
# CONFIG
# -------------------------
MILVUS_URI = os.getenv("MILVUS_URI", "http://localhost:19530")
SCHEMA_COLLECTION = os.getenv("SCHEMA_COLLECTION", "form_schema_index")

DENSE_DIM = 1024
TOP_K_SCHEMA = 8          # how many schema fields to consider
SCORE_THRESHOLD = 0.0     # COSINE similarity; 0.0 keeps all top-k


# -------------------------
# LANGGRAPH STATE
# -------------------------
class RewriteState(TypedDict):
    # Input
    user_query: str

    # Outputs (filled by node)
    schema_hits: List[Dict[str, Any]]
    structured_query: Dict[str, Any]


# -------------------------
# MILVUS CLIENT
# -------------------------
client = MilvusClient(uri=MILVUS_URI)


# -------------------------
# BGEM3 EMBEDDINGS
# -------------------------
print("Loading BGE-M3 FlagEmbedding model for rewrite...")
embed_model = BGEM3FlagModel("BAAI/bge-m3", use_fp16=True)


def get_bgem3_embedding(text: str) -> List[float]:
    """
    Use BGEM3FlagModel to get a dense 1024-d embedding.
    We only use dense for schema rewrite collection.
    """
    out = embed_model.encode(
        text,
        return_dense=True,
        return_sparse=False,
        normalize_embeddings=True,
    )
    vec = out["dense_vecs"][0]
    if len(vec) != DENSE_DIM:
        print(f"âš ï¸ BGEM3 dim mismatch: expected {DENSE_DIM}, got {len(vec)}")
    return vec


# -------------------------
# SCHEMA SEARCH
# -------------------------
def search_schema_in_milvus(query: str, k: int = TOP_K_SCHEMA) -> List[Dict[str, Any]]:
    """
    Vector search against form_schema_index using BGE-M3 embedding.
    Returns a list[dict] with label/prop/section/subsection + score.
    """
    q_vec = get_bgem3_embedding(query)

    res = client.search(
        collection_name=SCHEMA_COLLECTION,
        data=[q_vec],
        anns_field="dense",
        limit=k,
        output_fields=["Question_label", "Prop", "Section", "Subsection"],
        search_params={
            "metric_type": "COSINE",
            "params": {},
        },
    )

    hits: List[Dict[str, Any]] = []
    if not res:
        return hits

    for hit in res[0]:
        entity = hit.get("entity", {})
        score = hit.get("distance")
        # For COSINE in Milvus, "distance" is similarity when metric_type=COSINE
        hits.append(
            {
                "id": hit.get("id"),
                "score": score,
                "Question_label": entity.get("Question_label", ""),
                "Prop": entity.get("Prop", ""),
                "Section": entity.get("Section", ""),
                "Subsection": entity.get("Subsection", ""),
            }
        )

    return hits


# -------------------------
# SIMPLE RULE-BASED "REWRITE"
# -------------------------
def build_structured_query(
    user_query: str,
    schema_hits: List[Dict[str, Any]],
    score_threshold: float = SCORE_THRESHOLD,
) -> Dict[str, Any]:
    """
    Convert top schema hits into a simple structured JSON filter.

    No LLM here: we just pick the best matches from Milvus.
    """
    filters: List[Dict[str, str]] = []

    for h in schema_hits:
        score = h.get("score") or 0.0
        # If you want to drop weak matches, you can set SCORE_THRESHOLD > 0
        if score < score_threshold:
            continue

        filters.append(
            {
                "prop": h.get("Prop", ""),
                "section": h.get("Section", "") or "",
                "subsection": h.get("Subsection", "") or "",
            }
        )

    # very basic "rewrite" string without LLM
    if filters:
        prop_list = [f["prop"] for f in filters if f["prop"]]
        rewrite_str = (
            f"Use fields: {', '.join(prop_list)} for the query: {user_query}"
            if prop_list
            else user_query
        )
    else:
        rewrite_str = user_query

    return {
        "filters": filters,
        "original_query": user_query,
        "rewrite": rewrite_str,
    }


# -------------------------
# LANGGRAPH NODE
# -------------------------
def rewrite_query_node(state: RewriteState) -> Dict[str, Any]:
    """
    Node:
      input : state['user_query']
      output: state['schema_hits'], state['structured_query']

    Uses only:
      - BGEM3 embeddings
      - Milvus search
      - Rule-based conversion to JSON filters
    """
    user_query = state["user_query"]

    # 1) Vector search against schema collection
    schema_hits = search_schema_in_milvus(user_query, k=TOP_K_SCHEMA)

    # 2) Build structured query JSON (no LLM)
    structured = build_structured_query(user_query, schema_hits)

    return {
        "schema_hits": schema_hits,
        "structured_query": structured,
    }


# -------------------------
# BUILD GRAPH
# -------------------------
builder = StateGraph(RewriteState)

builder.add_node("rewrite_query", rewrite_query_node)
builder.add_edge(START, "rewrite_query")
builder.add_edge("rewrite_query", END)

rewrite_graph = builder.compile()


if __name__ == "__main__":
    # quick manual test
    test_state: RewriteState = {
        "user_query": "Get all PAN and GSTIN fields for billing address"
    }

    result = rewrite_graph.invoke(test_state)

    from pprint import pprint

    print("\n=== Schema hits ===")
    pprint(result["schema_hits"])

    print("\n=== Structured query ===")
    pprint(result["structured_query"])











# rewrite_query_ollama_bgem3.py
"""
LangGraph node for query rewrite using:
- Ollama bge-m3 embeddings  (http://localhost:11434/api/embeddings)
- Milvus for schema search
- Rule-based conversion to JSON filters (NO GPT / NO OpenAI)

Collection used: form_schema_index

Expected fields in `form_schema_index`:
  - Question_label (VARCHAR)
  - Prop           (VARCHAR)
  - Section        (VARCHAR)
  - Subsection     (VARCHAR)
  - dense          (FLOAT_VECTOR, 1024)   <-- from Ollama bge-m3
"""

from typing import List, Dict, Any
from typing_extensions import TypedDict
import os
import requests

from langgraph.graph import StateGraph, START, END
from pymilvus import MilvusClient


# -------------------------
# CONFIG
# -------------------------
MILVUS_URI = os.getenv("MILVUS_URI", "http://localhost:19530")
SCHEMA_COLLECTION = os.getenv("SCHEMA_COLLECTION", "form_schema_index")

# Ollama settings
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434/api/embeddings")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "bge-m3")

DENSE_DIM = 1024
TOP_K_SCHEMA = 8          # how many schema fields to consider
SCORE_THRESHOLD = 0.0     # keep all; bump this up to drop weak matches


# -------------------------
# LANGGRAPH STATE
# -------------------------
class RewriteState(TypedDict):
    # Input
    user_query: str

    # Outputs (filled by node)
    schema_hits: List[Dict[str, Any]]
    structured_query: Dict[str, Any]


# -------------------------
# MILVUS CLIENT
# -------------------------
client = MilvusClient(uri=MILVUS_URI)


# -------------------------
# OLLAMA bge-m3 EMBEDDINGS
# -------------------------
def get_bgem3_embedding(text: str) -> List[float]:
    """
    Call Ollama /api/embeddings with bge-m3 and return a 1024-dim vector.

    This MUST match how you embedded when ingesting form_schema_index.
    """
    resp = requests.post(
        OLLAMA_URL,
        json={
            "model": OLLAMA_MODEL,
            "prompt": text,   # use "prompt" to be consistent with your ingest script
        },
        timeout=120,
    )
    resp.raise_for_status()
    data = resp.json()

    emb = data.get("embedding")
    if emb is None:
        raise RuntimeError(f"No 'embedding' field in Ollama response: {data}")

    if len(emb) != DENSE_DIM:
        print(f"âš ï¸ Warning: expected dim {DENSE_DIM}, got {len(emb)}")

    return emb


# -------------------------
# SCHEMA SEARCH
# -------------------------
def search_schema_in_milvus(query: str, k: int = TOP_K_SCHEMA) -> List[Dict[str, Any]]:
    """
    Vector search against form_schema_index using bge-m3 embedding from Ollama.
    Returns a list[dict] with label/prop/section/subsection + score.
    """
    q_vec = get_bgem3_embedding(query)

    res = client.search(
        collection_name=SCHEMA_COLLECTION,
        data=[q_vec],
        anns_field="dense",
        limit=k,
        output_fields=["Question_label", "Prop", "Section", "Subsection"],
        search_params={
            "metric_type": "COSINE",
            "params": {},
        },
    )

    hits: List[Dict[str, Any]] = []
    if not res:
        return hits

    # res is List[List[hit]]; one query vector => res[0]
    for hit in res[0]:
        entity = hit.get("entity", {})
        score = hit.get("distance")  # for COSINE this is similarity / distance depending on Milvus config
        hits.append(
            {
                "id": hit.get("id"),
                "score": score,
                "Question_label": entity.get("Question_label", ""),
                "Prop": entity.get("Prop", ""),
                "Section": entity.get("Section", ""),
                "Subsection": entity.get("Subsection", ""),
            }
        )

    return hits


# -------------------------
# SIMPLE RULE-BASED "REWRITE"
# -------------------------
def build_structured_query(
    user_query: str,
    schema_hits: List[Dict[str, Any]],
    score_threshold: float = SCORE_THRESHOLD,
) -> Dict[str, Any]:
    """
    Convert top schema hits into a simple structured JSON filter.

    No LLM here: we just pick the best matches from Milvus.
    """
    filters: List[Dict[str, str]] = []

    for h in schema_hits:
        score = h.get("score") or 0.0
        # If you want to drop weak matches, set SCORE_THRESHOLD > 0
        if score < score_threshold:
            continue

        filters.append(
            {
                "prop": h.get("Prop", ""),
                "section": h.get("Section", "") or "",
                "subsection": h.get("Subsection", "") or "",
            }
        )

    # Very basic "rewrite" string (just for logging/debug)
    if filters:
        prop_list = [f["prop"] for f in filters if f["prop"]]
        rewrite_str = (
            f"Use fields: {', '.join(prop_list)} for the query: {user_query}"
            if prop_list
            else user_query
        )
    else:
        rewrite_str = user_query

    return {
        "filters": filters,
        "original_query": user_query,
        "rewrite": rewrite_str,
    }


# -------------------------
# LANGGRAPH NODE
# -------------------------
def rewrite_query_node(state: RewriteState) -> Dict[str, Any]:
    """
    Node:
      input : state['user_query']
      output: state['schema_hits'], state['structured_query']

    Uses only:
      - Ollama bge-m3 embeddings
      - Milvus search
      - Rule-based conversion to JSON filters
    """
    user_query = state["user_query"]

    # 1) Vector search on schema collection
    schema_hits = search_schema_in_milvus(user_query, k=TOP_K_SCHEMA)

    # 2) Build structured query JSON
    structured = build_structured_query(user_query, schema_hits)

    return {
        "schema_hits": schema_hits,
        "structured_query": structured,
    }


# -------------------------
# BUILD GRAPH
# -------------------------
builder = StateGraph(RewriteState)

builder.add_node("rewrite_query", rewrite_query_node)
builder.add_edge(START, "rewrite_query")
builder.add_edge("rewrite_query", END)

rewrite_graph = builder.compile()


if __name__ == "__main__":
    # Quick manual test
    test_state: RewriteState = {
        "user_query": "Get all PAN and GSTIN fields for billing address"
    }

    result = rewrite_graph.invoke(test_state)

    from pprint import pprint

    print("\n=== Schema hits ===")
    pprint(result["schema_hits"])

    print("\n=== Structured query ===")
    pprint(result["structured_query"])













from pymilvus import MilvusClient

client = MilvusClient(uri="http://localhost:19530")

def get_results_in_prop_order(structured_query, limit=10):
    ordered_results = []

    for f in structured_query["filters"]:
        expr_parts = []

        if f.get("prop"):
            expr_parts.append(f"Prop == '{f['prop']}'")
        if f.get("section"):
            expr_parts.append(f"Section == '{f['section']}'")
        if f.get("subsection"):
            expr_parts.append(f"Subsection == '{f['subsection']}'")

        expr = " and ".join(expr_parts)
        # Query only this propâ€™s rows
        rows = client.query(
            collection_name="form_field_values",   # your main collection
            filter=expr,
            output_fields=[
                "Question_label",
                "Prop",
                "Section",
                "Subsection",
                "Value",
            ],
            limit=limit,  # per-prop cap
        )

        ordered_results.extend(rows)

        if len(ordered_results) >= limit:
            break

    return ordered_results[:limit]


results = get_results_in_prop_order(structured_query, limit=10)

for r in results:
    print(r["Prop"], "|", r["Question_label"], "|", r.get("Value"))