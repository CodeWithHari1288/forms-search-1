#!/usr/bin/env python3
import os, glob, json, ssl
import hashlib
import numpy as np
import pandas as pd
import redis
from dotenv import load_dotenv
from ollama import Client
from redis.commands.search.indexDefinition import IndexDefinition, IndexType
from redis.commands.search.field import TextField, TagField, VectorField

load_dotenv()

# ---- Config ----
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))
REDIS_USERNAME = os.getenv("REDIS_USERNAME") or None
REDIS_PASSWORD = os.getenv("REDIS_PASSWORD") or None
REDIS_SSL = os.getenv("REDIS_SSL", "false").lower() == "true"
SSL_CA   = os.getenv("REDIS_SSL_CA_CERT") or None
SSL_CERT = os.getenv("REDIS_SSL_CLIENT_CERT") or None
SSL_KEY  = os.getenv("REDIS_SSL_CLIENT_KEY") or None

OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://localhost:11434")

INDEX_NAME  = os.getenv("INDEX_NAME", "idx:forms")
KEY_PREFIX  = os.getenv("KEY_PREFIX", "form:")
CSV_DIR     = os.getenv("CSV_DIR", "./data")
FORM_ID_DEF = os.getenv("DEFAULT_FORM_ID", "A")  # fallback if crfId row not present
VECTOR_DIM  = int(os.getenv("VECTOR_DIM", "1024"))

# ---- Connect ----
ssl_ctx = None
if REDIS_SSL:
    ssl_ctx = ssl.create_default_context(cafile=SSL_CA) if SSL_CA else ssl.create_default_context()
    if SSL_CERT and SSL_KEY:
        ssl_ctx.load_cert_chain(certfile=SSL_CERT, keyfile=SSL_KEY)

r = redis.Redis(
    host=REDIS_HOST,
    port=REDIS_PORT,
    username=REDIS_USERNAME,
    password=REDIS_PASSWORD,
    ssl=REDIS_SSL,
    ssl_ca_certs=SSL_CA if SSL_CA else None,
    ssl_certfile=SSL_CERT if SSL_CERT else None,
    ssl_keyfile=SSL_KEY if SSL_KEY else None,
    ssl_cert_reqs=ssl.CERT_REQUIRED if (REDIS_SSL and SSL_CA) else None,
    ssl_context=ssl_ctx if REDIS_SSL else None,
    decode_responses=False,
)
r.ping()
print("[ok] Connected to Redis.")

ollama = Client(host=OLLAMA_HOST)
ollama.show("bge-m3")  # verify availability

# ---- Embeddings ----
def embed_text(text: str) -> list[float]:
    resp = ollama.embeddings(model="bge-m3", prompt=text)
    vec = resp["embedding"]
    if len(vec) != VECTOR_DIM:
        raise ValueError(f"Expected {VECTOR_DIM}-D vector, got {len(vec)}")
    return vec  # keep as JSON float array

# ---- Index (ON JSON) ----
def ensure_index():
    try:
        r.ft(INDEX_NAME).info()
        print(f"[ok] Index {INDEX_NAME} exists.")
        return
    except Exception:
        pass

    schema = (
        # TEXT/BM25
        TextField("$.text",             as_name="text"),
        TextField("$.label",            as_name="label"),
        TextField("$.propertyname",     as_name="propertyname"),
        TextField("$.value",            as_name="value"),
        TextField("$.question_context", as_name="question_context"),
        TextField("$.repeatable",       as_name="repeatable"),
        TextField("$.pointer",          as_name="pointer"),

        # TAG filters
        TagField("$.form_id",           as_name="form_id"),
        TagField("$.section",           as_name="section"),
        TagField("$.subsection",        as_name="subsection"),
        TagField("$.question_id",       as_name="question_id"),
        TagField("$.status",            as_name="status"),

        # VECTOR (HNSW, COSINE, 1024-d)
        VectorField("$.vec", "HNSW",
            {"TYPE":"FLOAT32","DIM":VECTOR_DIM,"DISTANCE_METRIC":"COSINE","M":16,"EF_CONSTRUCTION":200,"EF_RUNTIME":64},
            as_name="vec"),
    )
    definition = IndexDefinition(prefix=[KEY_PREFIX], index_type=IndexType.JSON)
    r.ft(INDEX_NAME).create_index(schema, definition=definition)
    print(f"[ok] Created index {INDEX_NAME} (ON JSON).")

# ---- Helpers ----
def normalize_prop(s: str) -> str:
    return (s or "").strip().lower().replace(" ", "")

def extract_form_id_from_df(df: pd.DataFrame) -> str:
    """
    Find the row whose Prop equals 'crfId' (case/space-insensitive),
    and return its 'value'. If not found, use DEFAULT_FORM_ID.
    """
    if "Prop" not in df.columns or "value" not in df.columns:
        return FORM_ID_DEF

    mask = df["Prop"].astype(str).map(normalize_prop).eq("crfid")
    candidates = df.loc[mask, "value"].dropna().astype(str).str.strip()
    if len(candidates) == 0:
        print("[warn] crfId row not found; using DEFAULT_FORM_ID")
        return FORM_ID_DEF

    # If multiple crfId rows exist, take the first non-empty and warn on mismatch
    form_id = candidates.iloc[0]
    if (candidates != form_id).any():
        print(f"[warn] Multiple crfId values found; using '{form_id}'")

    if not form_id:
        print("[warn] crfId value empty; using DEFAULT_FORM_ID")
        return FORM_ID_DEF

    return form_id

def row_to_doc(row: pd.Series, form_id: str) -> dict:
    # CSV columns:
    # Prop, question_id, question_label, section, sub_section,
    # question_context, repeatable, value, json_pointer
    label = str(row.get("question_label", "") or "")
    prop  = str(row.get("Prop", "") or "")
    sec   = str(row.get("section", "") or "")
    sub   = str(row.get("sub_section", "") or "")
    ctx   = "" if pd.isna(row.get("question_context")) else str(row.get("question_context"))
    rep   = "" if pd.isna(row.get("repeatable")) else str(row.get("repeatable"))
    val   = "" if pd.isna(row.get("value")) else str(row.get("value"))
    ptr   = str(row.get("json_pointer", "") or "")
    qid   = str(row.get("question_id", "") or "")

    text = (f"Section: {sec}. Subsection: {sub}. "
            f"Field: {label}. Property: {prop}. "
            f"Context: {ctx}. Repeatable: {rep}.").strip()

    return {
        "form_id": form_id,         # from crfId row
        "section": sec,
        "subsection": sub,
        "label": label,
        "propertyname": prop,
        "value": val,
        "pointer": ptr,
        "text": text,
        "question_context": ctx,
        "repeatable": rep,
        "question_id": qid,         # indexed as TAG too
    }

def make_row_key(form_id: str, qid: str) -> str:
    """
    Deterministic key: form:{form_id}:qid:{question_id}
    Fallback to a stable hash if question_id missing (rare).
    """
    qid = (qid or "").strip()
    if qid:
        return f"{KEY_PREFIX}{form_id}:qid:{qid}"
    h = hashlib.sha1(f"{form_id}|no_qid".encode()).hexdigest()[:12]
    return f"{KEY_PREFIX}{form_id}:row:{h}"

# ---- Ingest ----
def ingest_csv(file_path: str):
    df = pd.read_csv(file_path)

    required = [
        "Prop","question_id","question_label","section","sub_section",
        "question_context","repeatable","value","json_pointer"
    ]
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"{os.path.basename(file_path)} missing columns: {missing}")

    # 1) derive form_id from the special 'crfId' row
    form_id = extract_form_id_from_df(df)

    # 2) skip the crfId row from ingestion (treat as metadata, not a field)
    is_crfid = df["Prop"].astype(str).map(normalize_prop).eq("crfid")
    df_data = df.loc[~is_crfid].copy()

    total = 0
    for _, row in df_data.iterrows():
        doc = row_to_doc(row, form_id)
        doc["vec"] = embed_text(doc["text"])

        key = make_row_key(form_id, doc.get("question_id",""))
        # Upsert: overwrite if exists (idempotent)
        r.json().set(key, "$", doc)
        total += 1
    return total, form_id

def ingest_folder(csv_dir: str):
    files = sorted(glob.glob(os.path.join(csv_dir, "*.csv")))
    if not files:
        print(f"[warn] no CSV files in {csv_dir}")
        return
    grand = 0
    for f in files:
        print(f"[info] ingesting {os.path.basename(f)}")
        count, fid = ingest_csv(f)
        print(f"[ok] {count} rows (form_id={fid})")
        grand += count
    print(f"[done] total rows ingested: {grand}")

if __name__ == "__main__":
    ensure_index()
    ingest_folder(CSV_DIR)








def get_bge_m3_vector(ollama_client, text: str, dim: int = 1024) -> list[float]:
    resp = ollama_client.embeddings(model="bge-m3", prompt=text)

    # Accept several shapes/keys
    vec = resp.get("embedding")
    if vec is None:
        vec = resp.get("embeddings")

    # Flatten if nested [[...]]
    if isinstance(vec, list) and len(vec) > 0 and isinstance(vec[0], list):
        vec = vec[0]

    if not isinstance(vec, list):
        raise ValueError(f"Unexpected embedding payload type: {type(vec)}")

    n = len(vec)
    if n != dim:
        raise ValueError(f"Embedding DIM mismatch: expected {dim}, got {n}")

    # Ensure numeric floats (not numpy types) for JSON; cast later for bytes
    return [float(x) for x in vec]